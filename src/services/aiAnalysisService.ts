import { AISettings, AIAnalysisRequest, AIAnalysisResult, Correction, CorrectionContext } from '../types/interfaces';
import { AIClientFactory } from '../api/clientFactory';
import { AI_PROMPTS, MODEL_TOKEN_LIMITS } from '../constants/aiModels';
import { estimateAnalysisTokenUsage, estimateCost } from '../utils/tokenEstimator';
import { Logger } from '../utils/logger';

export class AIAnalysisService {
  constructor(private settings: AISettings) {}

  /**
   * ê° ì˜¤ë¥˜ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
   */
  private extractCorrectionContexts(request: AIAnalysisRequest): CorrectionContext[] {
    const { originalText, corrections, contextWindow = 50, currentStates } = request;
    const contexts: CorrectionContext[] = [];

    corrections.forEach((correction, index) => {
      // ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ ìœ„ì¹˜ ì°¾ê¸°
      const errorIndex = originalText.indexOf(correction.original);
      if (errorIndex === -1) {
        Logger.warn(`ì˜¤ë¥˜ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: "${correction.original}"`);
        // ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ë¹ˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
        contexts.push({
          correctionIndex: index,
          original: correction.original,
          corrected: correction.corrected,
          help: correction.help,
          contextBefore: '',
          contextAfter: '',
          fullContext: correction.original,
        });
        return;
      }

      // ì•ë’¤ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
      const startIndex = Math.max(0, errorIndex - contextWindow);
      const endIndex = Math.min(originalText.length, errorIndex + correction.original.length + contextWindow);
      
      const contextBefore = originalText.slice(startIndex, errorIndex);
      const contextAfter = originalText.slice(errorIndex + correction.original.length, endIndex);
      const fullContext = originalText.slice(startIndex, endIndex);

      const stateInfo = currentStates ? currentStates[index] : undefined;

      contexts.push({
        correctionIndex: index,
        original: correction.original,
        corrected: correction.corrected,
        help: correction.help,
        contextBefore: contextBefore.trim(),
        contextAfter: contextAfter.trim(),
        fullContext: fullContext.trim(),
        currentState: stateInfo?.state,
        currentValue: stateInfo?.value,
      });
    });

    return contexts;
  }

  /**
   * AI ë¶„ì„ì— í•„ìš”í•œ í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì •í•©ë‹ˆë‹¤.
   */
  estimateTokenUsage(request: AIAnalysisRequest): {
    inputTokens: number;
    estimatedOutputTokens: number;
    totalEstimated: number;
    estimatedCost: string;
  } {
    const correctionContexts = this.extractCorrectionContexts(request);
    const tokenUsage = estimateAnalysisTokenUsage(correctionContexts);
    const cost = estimateCost(tokenUsage.totalEstimated, this.settings.provider);
    
    return {
      ...tokenUsage,
      estimatedCost: cost
    };
  }

  /**
   * ìµœì ì˜ ë°°ì¹˜ í¬ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
   * â­ JSON ì˜ë¦¼ ë°©ì§€ë¥¼ ìœ„í•´ ë³´ìˆ˜ì  ë°°ì¹˜ í¬ê¸° ì ìš©
   */
  private calculateOptimalBatchSize(correctionContexts: CorrectionContext[], hasMorphemeInfo = false): number {
    if (correctionContexts.length === 0) return 5;
    
    // í‰ê·  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
    const avgContextLength = correctionContexts.reduce((sum, ctx) => sum + ctx.fullContext.length, 0) / correctionContexts.length;
    const systemPromptLength = AI_PROMPTS.analysisSystem.length;
    
    // ëª¨ë¸ë³„ ì…ë ¥ í† í° ì œí•œ (ëŒ€ëµì ìœ¼ë¡œ ê³„ì‚°)
    const maxInputTokens = this.getModelMaxInputTokens(this.settings.model);
    
    // ğŸ”§ JSON ì‘ë‹µ ì˜ë¦¼ ë°©ì§€ë¥¼ ìœ„í•´ ë³´ìˆ˜ì ìœ¼ë¡œ ê³„ì‚°
    // ê° êµì •ë‹¹ JSON ì‘ë‹µ: ~120ì ì˜ˆìƒ 
    // 15ê°œ = 1800ì â†’ í† í° ì œí•œ ì´ˆê³¼ ìœ„í—˜
    let optimalSize = 6; // ì•ˆì „í•œ ê¸°ë³¸ê°’
    
    if (avgContextLength < 50) {
      optimalSize = 8; // ë§¤ìš° ì§§ì€ ì»¨í…ìŠ¤íŠ¸
    } else if (avgContextLength < 100) {
      optimalSize = 6; // ì§§ì€ ì»¨í…ìŠ¤íŠ¸  
    } else if (avgContextLength < 200) {
      optimalSize = 4; // ë³´í†µ ì»¨í…ìŠ¤íŠ¸
    } else {
      optimalSize = 3; // ê¸´ ì»¨í…ìŠ¤íŠ¸
    }
    
    // í˜•íƒœì†Œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì•½ê°„ ë” ë³´ìˆ˜ì ìœ¼ë¡œ
    if (hasMorphemeInfo) {
      optimalSize = Math.max(3, optimalSize - 1);
    }
    
    Logger.debug(`JSON ì˜ë¦¼ ë°©ì§€ ë°°ì¹˜ í¬ê¸°: í‰ê·  ì»¨í…ìŠ¤íŠ¸ ${avgContextLength}ì, í˜•íƒœì†Œ: ${hasMorphemeInfo} â†’ ${optimalSize}ê°œì”© ì²˜ë¦¬`);
    
    return Math.min(optimalSize, 8); // ìµœëŒ€ 8ê°œë¡œ ì•ˆì „í•˜ê²Œ ì œí•œ
  }

  /**
   * ëª¨ë¸ë³„ ìµœëŒ€ ì…ë ¥ í† í°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ëŒ€ëµì ).
   */
  private getModelMaxInputTokens(model: string): number {
    // ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ ì…ë ¥ í† í°ì´ ì¶œë ¥ í† í°ë³´ë‹¤ í›¨ì”¬ ë§ìŒ
    const outputLimit = this.getModelMaxTokens(model);
    return outputLimit * 10; // ë³´ìˆ˜ì ìœ¼ë¡œ ê³„ì‚°
  }

  /**
   * ì˜¤ë¥˜ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•©ë‹ˆë‹¤.
   */
  private createBatches(correctionContexts: CorrectionContext[], maxBatchSize: number = 10): CorrectionContext[][] {
    const batches: CorrectionContext[][] = [];
    for (let i = 0; i < correctionContexts.length; i += maxBatchSize) {
      batches.push(correctionContexts.slice(i, i + maxBatchSize));
    }
    return batches;
  }

  /**
   * ë‹¨ì¼ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
   */
  private async processBatch(
    batch: CorrectionContext[], 
    batchIndex: number, 
    totalBatches: number,
    client: any,
    adjustedMaxTokens: number,
    model: string,
    morphemeInfo?: any  // â­ NEW: í˜•íƒœì†Œ ì •ë³´ ì¶”ê°€
  ): Promise<AIAnalysisResult[]> {
    Logger.debug(`ë°°ì¹˜ ${batchIndex + 1}/${totalBatches} ì²˜ë¦¬ ì¤‘ (${batch.length}ê°œ ì˜¤ë¥˜)`);

    const systemPrompt = AI_PROMPTS.analysisSystem;
    
    // â­ NEW: í˜•íƒœì†Œ ì •ë³´ê°€ ìˆìœ¼ë©´ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    const userPrompt = morphemeInfo 
      ? AI_PROMPTS.analysisUserWithMorphemes(batch, morphemeInfo)
      : AI_PROMPTS.analysisUserWithContext(batch);
    
    // â­ NEW: í˜•íƒœì†Œ ì •ë³´ ë¡œê¹…
    if (morphemeInfo) {
      Logger.debug(`í˜•íƒœì†Œ ì •ë³´ì™€ í•¨ê»˜ AI ë¶„ì„ ì§„í–‰ (í† í° ì ˆì•½ ëª¨ë“œ)`);
      Logger.debug(`í˜•íƒœì†Œ í† í° ìˆ˜: ${morphemeInfo.tokens?.length || 0}ê°œ`);
    }
    
    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ];

    const response = await client.chat(messages, adjustedMaxTokens, model);
    Logger.debug(`ë°°ì¹˜ ${batchIndex + 1} ì‘ë‹µ ìˆ˜ì‹ :`, response.substring(0, 100) + '...');

    return this.parseAIResponse(response, batch);
  }

  /**
   * AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ì¶¤ë²• ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ê³  ìµœì ì˜ ìˆ˜ì •ì‚¬í•­ì„ ì œì•ˆí•©ë‹ˆë‹¤.
   * â­ NEW: í˜•íƒœì†Œ ì •ë³´ í†µí•© ì§€ì›
   */
  async analyzeCorrections(request: AIAnalysisRequest, morphemeInfo?: any): Promise<AIAnalysisResult[]> {
    Logger.debug('analyzeCorrections ì‹œì‘:', {
      enabled: this.settings.enabled,
      provider: this.settings.provider,
      model: this.settings.model,
      correctionsCount: request.corrections.length
    });

    if (!this.settings.enabled) {
      throw new Error('AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
    }

    if (!AIClientFactory.hasValidApiKey(this.settings)) {
      const provider = this.settings.provider;
      const keyName = provider === 'openai' ? 'OpenAI API í‚¤' :
                     provider === 'anthropic' ? 'Anthropic API í‚¤' :
                     provider === 'google' ? 'Google API í‚¤' :
                     provider === 'ollama' ? 'Ollama ì—”ë“œí¬ì¸íŠ¸' : 'API í‚¤';
      throw new Error(`${keyName}ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”ŒëŸ¬ê·¸ì¸ ì„¤ì •ì—ì„œ ${provider} ì œê³µìì˜ ${keyName}ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.`);
    }

    // ëª¨ë¸ëª… ìœ íš¨ì„± ê²€ì‚¬
    if (!this.settings.model || this.settings.model.trim() === '') {
      throw new Error(`ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”ŒëŸ¬ê·¸ì¸ ì„¤ì •ì—ì„œ ${this.settings.provider} ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.`);
    }

    const client = AIClientFactory.createClient(this.settings);
    
    try {
      // ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
      const allContexts = this.extractCorrectionContexts(request);
      
      // ë¶„ì„ì´ í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ ì²˜ë¦¬ëœ ì»¨í…ìŠ¤íŠ¸ ë¶„ë¦¬
      const contextsToAnalyze = allContexts.filter(
        ctx => ctx.currentState !== 'original-kept' && ctx.currentState !== 'exception-processed'
      );
      const alreadyResolvedContexts = allContexts.filter(
        ctx => ctx.currentState === 'original-kept' || ctx.currentState === 'exception-processed'
      );

      Logger.debug(`ë¶„ì„ ëŒ€ìƒ: ${contextsToAnalyze.length}ê°œ, ì´ë¯¸ ì²˜ë¦¬ë¨: ${alreadyResolvedContexts.length}ê°œ`);

      let aiResults: AIAnalysisResult[] = [];

      if (contextsToAnalyze.length > 0) {
        // ë°°ì¹˜ í¬ê¸° ê²°ì • (í˜•íƒœì†Œ ì •ë³´ ìœ ë¬´ ê³ ë ¤)
        const maxBatchSize = this.calculateOptimalBatchSize(contextsToAnalyze, !!morphemeInfo);
        
        Logger.debug('ë¶„ì„ ìš”ì²­ ì „ì†¡ ì¤‘...', {
          provider: this.settings.provider,
          model: this.settings.model,
          totalCorrections: contextsToAnalyze.length,
          batchSize: maxBatchSize,
          estimatedBatches: Math.ceil(contextsToAnalyze.length / maxBatchSize),
          contextWindow: request.contextWindow || 50,
          maxTokens: this.settings.maxTokens,
          apiKeySet: !!this.getApiKey()
        });

        // ë°°ì¹˜ ìƒì„±
        const batches = this.createBatches(contextsToAnalyze, maxBatchSize);
        Logger.debug(`${batches.length}ê°œ ë°°ì¹˜ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.`);

        // ëª¨ë¸ë³„ í† í° ì œí•œì— ë§ê²Œ ì¡°ì •
        const adjustedMaxTokens = this.adjustTokensForModel(this.settings.maxTokens, this.settings.model);
        
        // â­ NEW: í˜•íƒœì†Œ ì •ë³´ ë¡œê¹…
        if (morphemeInfo) {
          Logger.debug('í˜•íƒœì†Œ ì •ë³´ í™œìš© AI ë¶„ì„ ì‹œì‘:', {
            tokensCount: morphemeInfo.tokens?.length || 0,
            sentences: morphemeInfo.sentences?.length || 0,
            language: morphemeInfo.language || 'unknown'
          });
        }

        // ëª¨ë“  ë°°ì¹˜ ì²˜ë¦¬
        for (let i = 0; i < batches.length; i++) {
          try {
            if (request.onProgress) {
              const progressMsg = morphemeInfo 
                ? `AI + í˜•íƒœì†Œ ë¶„ì„ ì¤‘... (${Math.round(((i + 1) / batches.length) * 100)}%)`
                : `AI ë¶„ì„ ì¤‘... (${Math.round(((i + 1) / batches.length) * 100)}%)`;
              request.onProgress(i + 1, batches.length, progressMsg);
            }
            
            const batchResults = await this.processBatch(
              batches[i], 
              i, 
              batches.length, 
              client, 
              adjustedMaxTokens, 
              this.settings.model,
              morphemeInfo  // â­ NEW: í˜•íƒœì†Œ ì •ë³´ ì „ë‹¬
            );
            
            aiResults.push(...batchResults);
            
            if (i < batches.length - 1) {
              await new Promise(resolve => setTimeout(resolve, 500));
            }
          } catch (error) {
            Logger.error(`ë°°ì¹˜ ${i + 1} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
          }
        }
        Logger.debug(`AI ë¶„ì„ ì™„ë£Œ: ${aiResults.length}ê°œ ê²°ê³¼ ìˆ˜ì§‘ë¨`);
      }

      // ì´ë¯¸ ì²˜ë¦¬ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²°ê³¼ì— ì¶”ê°€
      const resolvedResults: AIAnalysisResult[] = alreadyResolvedContexts.map(ctx => ({
        correctionIndex: ctx.correctionIndex,
        selectedValue: ctx.currentValue || ctx.original,
        isExceptionProcessed: ctx.currentState === 'exception-processed',
        isOriginalKept: ctx.currentState === 'original-kept',
        confidence: 100,
        reasoning: 'ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ í•­ëª©ì…ë‹ˆë‹¤.'
      }));

      // AI ê²°ê³¼ì™€ ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ í•©ì¹˜ê³  ì •ë ¬
      const allResults = [...aiResults, ...resolvedResults];
      allResults.sort((a, b) => a.correctionIndex - b.correctionIndex);
      
      Logger.debug(`ìµœì¢… ì²˜ë¦¬ ì™„ë£Œ: ${allResults.length}ê°œ ê²°ê³¼ ë°˜í™˜`);
      
      return allResults;
    } catch (error) {
      Logger.error('ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
      throw new Error(`AI ë¶„ì„ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  /**
   * AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²°ê³¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
   */
  private parseAIResponse(response: string, correctionContexts: CorrectionContext[]): AIAnalysisResult[] {
    try {
      // JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
      let parsedResponse: any[];
      
      // 1. ë¨¼ì € ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
      let cleanedResponse = response.trim();
      
      // ```json ... ``` íŒ¨í„´ ì œê±°
      const codeBlockMatch = cleanedResponse.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
      if (codeBlockMatch) {
        cleanedResponse = codeBlockMatch[1].trim();
      }
      
      // 2. JSON ë°°ì—´ íŒ¨í„´ ì°¾ê¸° (ë” ê´€ëŒ€í•œ ë§¤ì¹­)
      let jsonString = '';
      const jsonArrayMatch = cleanedResponse.match(/\[[\s\S]*\]/);
      if (jsonArrayMatch) {
        jsonString = jsonArrayMatch[0];
      } else {
        jsonString = cleanedResponse;
      }
      
      // 3. ì˜ë¦° JSON ë³µêµ¬ ì‹œë„ (ê°œì„ ëœ ë¡œì§)
      if (!jsonString.endsWith(']') && jsonString.includes('[')) {
        Logger.warn('JSONì´ ì˜ë¦° ê²ƒìœ¼ë¡œ ë³´ì„, ê°•í™”ëœ ë³µêµ¬ ì‹œë„');
        
        // 3-1. ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ ì°¾ê¸°
        let lastCompleteObjectIndex = -1;
        let braceCount = 0;
        let inString = false;
        let escapeNext = false;
        
        for (let i = 0; i < jsonString.length; i++) {
          const char = jsonString[i];
          
          if (escapeNext) {
            escapeNext = false;
            continue;
          }
          
          if (char === '\\') {
            escapeNext = true;
            continue;
          }
          
          if (char === '"') {
            inString = !inString;
            continue;
          }
          
          if (!inString) {
            if (char === '{') {
              braceCount++;
            } else if (char === '}') {
              braceCount--;
              if (braceCount === 0) {
                lastCompleteObjectIndex = i;
              }
            }
          }
        }
        
        // 3-2. ë³µêµ¬ ì‹œë„
        if (lastCompleteObjectIndex > 0) {
          jsonString = jsonString.substring(0, lastCompleteObjectIndex + 1) + ']';
          Logger.debug('ê³ ê¸‰ JSON ë³µêµ¬ ì™„ë£Œ');
        } else {
          // 3-3. ê°„ë‹¨í•œ ë³µêµ¬ (ê¸°ì¡´ ë°©ì‹)
          const lastBraceIndex = jsonString.lastIndexOf('}');
          if (lastBraceIndex > 0) {
            jsonString = jsonString.substring(0, lastBraceIndex + 1) + ']';
            Logger.debug('ê¸°ë³¸ JSON ë³µêµ¬ ì™„ë£Œ');
          }
        }
      }
      
      Logger.debug('íŒŒì‹±í•  JSON (ì²« 200ì):', jsonString.substring(0, 200) + (jsonString.length > 200 ? '...' : ''));
      
      // ğŸ”§ JSON íŒŒì‹± ì‹œë„ + ì¶”ê°€ ë³µêµ¬ ë¡œì§
      try {
        parsedResponse = JSON.parse(jsonString);
      } catch (parseError) {
        Logger.warn('ì´ˆê¸° JSON íŒŒì‹± ì‹¤íŒ¨, ì¶”ê°€ ë³µêµ¬ ì‹œë„:', parseError);
        
        // ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° ì‹œë„
        let fixedJson = jsonString.replace(/,\s*$/, '');
        if (!fixedJson.endsWith(']')) {
          fixedJson += ']';
        }
        
        try {
          parsedResponse = JSON.parse(fixedJson);
          Logger.debug('ì‰¼í‘œ ì œê±°ë¡œ JSON ë³µêµ¬ ì„±ê³µ');
        } catch (secondError) {
          // ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ê°ì²´ ì œê±° ì‹œë„
          const lastCommaIndex = jsonString.lastIndexOf(',');
          if (lastCommaIndex > 0) {
            const cutJson = jsonString.substring(0, lastCommaIndex) + ']';
            try {
              parsedResponse = JSON.parse(cutJson);
              Logger.debug('ë¶ˆì™„ì „ ê°ì²´ ì œê±°ë¡œ JSON ë³µêµ¬ ì„±ê³µ');
            } catch (thirdError) {
              throw parseError; // ì›ë˜ ì˜¤ë¥˜ ë‹¤ì‹œ ë˜ì§€ê¸°
            }
          } else {
            throw parseError;
          }
        }
      }

      const results: AIAnalysisResult[] = [];

      for (const item of parsedResponse) {
        const batchIndex = parseInt(item.correctionIndex);
        
        if (isNaN(batchIndex) || batchIndex < 0 || batchIndex >= correctionContexts.length) {
          Logger.warn('ìœ íš¨í•˜ì§€ ì•Šì€ batchIndex:', batchIndex);
          continue;
        }

        const context = correctionContexts[batchIndex];
        const originalCorrectionIndex = context.correctionIndex;

        let selectedValue = item.selectedValue || '';
        
        const validOptions = [...context.corrected, context.original];
        if (!validOptions.includes(selectedValue)) {
          if (selectedValue === 'ì›ë³¸ìœ ì§€' || selectedValue === 'ì˜ˆì™¸ì²˜ë¦¬' || !selectedValue) {
            selectedValue = context.original;
            Logger.debug(`"${item.selectedValue}"ë¥¼ ì›ë³¸ "${context.original}"ë¡œ ë³€ê²½`);
          } else {
            const matchedOption = this.findBestMatch(selectedValue, validOptions);
            if (matchedOption) {
              Logger.debug(`"${selectedValue}"ë¥¼ ê°€ì¥ ìœ ì‚¬í•œ ì˜µì…˜ "${matchedOption}"ë¡œ ë§¤ì¹­`);
              selectedValue = matchedOption;
            } else {
              Logger.warn('ìœ íš¨í•˜ì§€ ì•Šì€ ì„ íƒê°’:', selectedValue, 'ê°€ëŠ¥í•œ ì˜µì…˜:', validOptions);
              selectedValue = context.original;
            }
          }
        }

        const isOriginalSelected = selectedValue === context.original;
        const isOriginalKept = isOriginalSelected && !item.isExceptionProcessed;

        results.push({
          correctionIndex: originalCorrectionIndex,
          selectedValue,
          isExceptionProcessed: item.isExceptionProcessed || false,
          isOriginalKept: isOriginalKept,
          confidence: Math.max(0, Math.min(100, parseInt(item.confidence) || 0)),
          reasoning: item.reasoning || 'ì´ìœ ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
        });
      }

      Logger.debug(`íŒŒì‹± ì™„ë£Œ: ${results.length}ê°œì˜ ê²°ê³¼ ì¶”ì¶œë¨`);
      
      const processedIndexes = new Set(results.map(r => r.correctionIndex));
      const missingContexts = correctionContexts.filter(ctx => !processedIndexes.has(ctx.correctionIndex));
      
      if (missingContexts.length > 0) {
        Logger.warn(`ëˆ„ë½ëœ ì˜¤ë¥˜ë“¤ (ì›ë³¸ ì¸ë±ìŠ¤): ${missingContexts.map(c => c.correctionIndex).join(', ')}`);
        
        missingContexts.forEach(context => {
          const defaultValue = context.corrected[0] || context.original;
          const isDefaultOriginal = defaultValue === context.original;
          
          results.push({
            correctionIndex: context.correctionIndex,
            selectedValue: defaultValue,
            isExceptionProcessed: false,
            isOriginalKept: isDefaultOriginal,
            confidence: 50,
            reasoning: 'AI ë¶„ì„ì—ì„œ ëˆ„ë½ë˜ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë¨'
          });
        });
        
        results.sort((a, b) => a.correctionIndex - b.correctionIndex);
      }
      
      return results;
    } catch (error) {
      Logger.error('ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜:', error);
      Logger.error('ì›ë³¸ ì‘ë‹µ (ì²« 500ì):', response.substring(0, 500));
      
      if (error instanceof SyntaxError) {
        throw new Error(`JSON í˜•ì‹ ì˜¤ë¥˜: ${error.message}. AI ì‘ë‹µì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.`);
      } else {
        throw new Error(`AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: ${error.message}`);
      }
    }
  }

  /**
   * ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
   */
  async fetchAvailableModels(): Promise<string[]> {
    try {
      return await AIClientFactory.fetchModels(this.settings);
    } catch (error) {
      Logger.error('ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:', error);
      return [];
    }
  }

  /**
   * AI ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
   */
  updateSettings(newSettings: AISettings): void {
    this.settings = newSettings;
  }

  /**
   * AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
   */
  isAvailable(): boolean {
    return this.settings.enabled && AIClientFactory.hasValidApiKey(this.settings);
  }

  /**
   * í˜„ì¬ ì„¤ì •ëœ ì œê³µì ë° ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
   */
  getProviderInfo(): { provider: string; model: string; available: boolean } {
    return {
      provider: this.settings.provider,
      model: this.settings.model,
      available: this.isAvailable()
    };
  }

  /**
   * í˜„ì¬ AI ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
   */
  getSettings(): AISettings {
    return this.settings;
  }

  /**
   * ëª¨ë¸ë³„ ìµœëŒ€ ì¶œë ¥ í† í°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
   */
  private getModelMaxTokens(model: string): number {
    return MODEL_TOKEN_LIMITS[model as keyof typeof MODEL_TOKEN_LIMITS] || 2048; // ê¸°ë³¸ê°’
  }

  /**
   * ìš”ì²­í•  í† í° ìˆ˜ë¥¼ ëª¨ë¸ ì œí•œì— ë§ê²Œ ì¡°ì •í•©ë‹ˆë‹¤.
   */
  private adjustTokensForModel(requestedTokens: number, model: string): number {
    const modelLimit = this.getModelMaxTokens(model);
    if (requestedTokens > modelLimit) {
      Logger.warn(`ìš”ì²­ëœ í† í° ìˆ˜(${requestedTokens})ê°€ ëª¨ë¸ ì œí•œ(${modelLimit})ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ${modelLimit}ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.`);
      return modelLimit;
    }
    return requestedTokens;
  }

  /**
   * í˜„ì¬ ì œê³µìì˜ API í‚¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
   */
  private getApiKey(): string {
    switch (this.settings.provider) {
      case 'openai':
        return this.settings.openaiApiKey;
      case 'anthropic':
        return this.settings.anthropicApiKey;
      case 'google':
        return this.settings.googleApiKey;
      case 'ollama':
        return this.settings.ollamaEndpoint;
      default:
        return '';
    }
  }

  /**
   * AIê°€ ë°˜í™˜í•œ ê°’ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ìœ íš¨í•œ ì˜µì…˜ì„ ì°¾ìŠµë‹ˆë‹¤.
   */
  private findBestMatch(aiValue: string, validOptions: string[]): string | null {
    // 1. ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²ƒì´ ìˆëŠ”ì§€ í™•ì¸ (ì´ë¯¸ ì²´í¬ë¨)
    if (validOptions.includes(aiValue)) {
      return aiValue;
    }

    // 2. ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•œ í•µì‹¬ í…ìŠ¤íŠ¸ë¡œ ë¹„êµ
    const cleanAiValue = aiValue.replace(/[\s\*\~\-\+\[\]]/g, '');
    
    for (const option of validOptions) {
      const cleanOption = option.replace(/[\s\*\~\-\+\[\]]/g, '');
      
      // í•µì‹¬ í…ìŠ¤íŠ¸ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
      if (cleanAiValue === cleanOption) {
        return option;
      }
      
      // AI ê°’ì´ ì˜µì…˜ì— í¬í•¨ë˜ê±°ë‚˜ ê·¸ ë°˜ëŒ€ì¸ ê²½ìš°
      if (cleanAiValue.includes(cleanOption) || cleanOption.includes(cleanAiValue)) {
        return option;
      }
    }

    // 3. í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ì‚¬ (ë§¤ìš° ìœ ì‚¬í•œ ê²½ìš°ë§Œ)
    let bestMatch = null;
    let bestScore = Infinity;
    
    for (const option of validOptions) {
      const distance = this.levenshteinDistance(aiValue, option);
      const similarity = 1 - distance / Math.max(aiValue.length, option.length);
      
      // 70% ì´ìƒ ìœ ì‚¬í•œ ê²½ìš°ë§Œ ê³ ë ¤
      if (similarity >= 0.7 && distance < bestScore) {
        bestMatch = option;
        bestScore = distance;
      }
    }

    return bestMatch;
  }

  /**
   * ë‘ ë¬¸ìì—´ ê°„ì˜ í¸ì§‘ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
   */
  private levenshteinDistance(str1: string, str2: string): number {
    const matrix = [];
    const n = str2.length;
    const m = str1.length;

    if (n === 0) return m;
    if (m === 0) return n;

    for (let i = 0; i <= n; i++) {
      matrix[i] = [i];
    }

    for (let j = 0; j <= m; j++) {
      matrix[0][j] = j;
    }

    for (let i = 1; i <= n; i++) {
      for (let j = 1; j <= m; j++) {
        if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          );
        }
      }
    }

    return matrix[n][m];
  }
}